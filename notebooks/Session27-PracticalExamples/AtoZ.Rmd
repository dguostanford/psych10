---
title: 'Session 27: AtoZ diet example'
output:
  html_document:
    df_print: paged
---

```{r echo=FALSE,message=FALSE}
library(dplyr)
library(ggplot2)
library(emmeans)
library(BayesFactor)
library(brms)
```

The "A TO Z" study (published in 2007 by Stanford Investigators led by Christopher Gardner; https://jamanetwork.com/journals/jama/fullarticle/205916) examined the effects of the Atkins, Zone, Ornish, and LEARN Diets on weight loss and other health risk factors in overweight premenopausal women.  Here you will examine the outputs of hypothetical analyses from that study and interpret them.  First we will generate some data based on the summary statistics reported in the paper.

```{r}

set.seed(123456)
# generate a dataset based on the results of Gardner et al.
dietDf = data.frame(diet=c(rep('Atkins',77),rep('Zone',79),
                           rep('LEARN',79),rep('Ornish',76))) %>%
  mutate(BMIChange12Months=ifelse(diet=='Atkins',rnorm(n=77,mean=-1.65,sd=2.54),
                                  ifelse(diet=='Zone',rnorm(n=79,mean=-0.53,sd=2.0),
                                  ifelse(diet=='LEARN',rnorm(n=79,mean=-0.92,sd=2.0),
                                         rnorm(n=76,mean=-0.77,sd=2.14) ))),
         physicalActivity=ifelse(diet=='Atkins',rnorm(n=77,mean=34,sd=6),
                                  ifelse(diet=='Zone',rnorm(n=79,mean=34,sd=6.0),
                                  ifelse(diet=='LEARN',rnorm(n=79,mean=34,sd=5.0),
                                         rnorm(n=76,mean=35,sd=7) ))))
summaryDf=dietDf %>% 
  group_by(diet) %>% 
  summarize(n=n(),
            meanBMIChange12Months=mean(BMIChange12Months),
            varBMIChange12Months=var(BMIChange12Months)) %>%
  mutate(crit_val_lower = qt(.05, n - 1),
         crit_val_upper = qt(.95, n - 1),
         ci.lower=meanBMIChange12Months+(sqrt(varBMIChange12Months)*crit_val_lower)/sqrt(n),
         ci.upper=meanBMIChange12Months+(sqrt(varBMIChange12Months)*crit_val_upper)/sqrt(n))
summaryDf

ggplot(summaryDf,aes(x=diet,y=meanBMIChange12Months)) +
  geom_point(size=2) + 
  geom_errorbar(aes(ymin = ci.lower, ymax = ci.upper), width = 0, size = 1) +
  ylab('mean BMI change over 12 months (+/- 95% CI)')

ggplot(dietDf,aes(BMIChange12Months,color=diet)) + 
  geom_density(size=1)

```

Let's run an ANOVA on BMI change to compare it across the four diets. It turns out that we don't actually need to generate the dummy-coded variables ourselves; if we give lm() a categorical variable, it will automatically generate them for us.

```{r}

lmResult=lm(BMIChange12Months ~ diet, data = dietDf)


```

The first thing we want to do is to critique the model to make sure that it is appropriate. One thing we can do is to look at the residuals from the model. In this case, we will plot the residuals for each individual grouped by diet. We will jitter the points so that we can see all of them.

```{r}
ggplot(data.frame(residuals=lmResult$residuals,diet=dietDf$diet),aes(x=diet,y=residuals)) +
  geom_point(position=position_jitter(.1))
```

There are no obvious differences in the residuals across conditions, suggesting that we can go ahead and interpret the model outputs, so let's look at the summary of the model fit.

```{r}
summary(lmResult)
```

If you look at the results you will see that it set Atkins as the baseline (since it was first alphabetically), and then created dummy variables for the other three values of the diet variable. The significant F test shows us that there is a significant difference between diets, but we should also note that the model doesn't actually account for much variance in the data; the R-squared value is only 0.03, showing that the model is only accounting for a few percent of the variance in weight loss.  Thus, we would not want to overinterpret this result.

The significant result also doesn't tell us which diets differ from which others. 
We can find out more by comparing means across conditions using emmeans():

```{r}
# compute the differences between each of the means
leastsquare = emmeans(lmResult, 
                      pairwise ~ diet,
                      adjust="tukey")
 
# display the results by grouping using letters

cld(leastsquare, 
    alpha=.05,  
    Letters=letters)$emmeans

```

This shows that Atkins and LEARN diets are significantly better than the Ornish or Zone diets in terms of 12-month weight loss, but they don't differ significantly from one another. 

#### Bayes factor
Let's say that we want to have a better way to describe the amount of evidence provided by the data.  One way we can do this is to compute a Bayes factor, which we can do by fitting the full model (including diet) and the reduced model (without diet) and the compare their fit. For the reduced model, we just include a 1, which tells the fitting program to only fit an intercept

```{r}
brmFullModel=brm(BMIChange12Months ~ diet, data = dietDf,save_all_pars = TRUE)
brmReducedModel=brm(BMIChange12Months ~ 1, data = dietDf,save_all_pars = TRUE)
bayes_factor(brmFullModel,brmReducedModel)
```

This shows us that there is very strong evidence (Bayes factor of nearly 100) for differences between the diets.

#### Categorical analysis

If we look more closely at the Garder paper, we will see that they report statistics on how many individuals in each group had been diagnosed with *metabolic syndrome*, which is a syndrome characterized by high blood pressure, high blood glucose, excess body fat around the waist, and abnormal cholesterol levels and is associated with increased risk for cardiovascular problems. Let's first add those data into the summary data frame:

```{r}
summaryDf=summaryDf %>% 
                    mutate(nMetSym=c(22,20,29,27),
                           nNoMetSym=n-nMetSym)
```

Let's say that we are interested in testing whether the difference in the rate of metabolic syndrome was significantly different between the groups, since this might make us concerned that these differences could have affected the results of the diet outcomes. 

We can test this using a standard chi-squared test to test against the null hypothesis that the probabilities are all the same.

```{r}
chisq.test(summaryDf$nMetSym,summaryDf$nNoMetSym)
```

This test shows that there is not a significant difference between means. However, it doesn't tell us how certain we are that there is no difference; remember that under NHST, we are always working under the assumption that the null is true unless the data show us enough evidence to cause us to reject this null hypothesis.

What if we want to quantify the evidence for or against the null?  We can do this using a Bayesian analysis. 

```{r}

bf = contingencyTableBF(as.matrix(summaryDf[,9:10]), sampleType = "indepMulti", fixedMargin = "cols")
bf
```


This shows us that the alternative hypothesis is 0.058 times more likely than the null hypothesis, which means that the null hypothesis is 1/0.058 ~ 17 times more likely than the alternative hypothesis given these data. This is fairly strong, if not completely overwhelming, evidence.
